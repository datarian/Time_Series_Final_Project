# Results {#results}

## Stationarity {#stationarity}
The last approach proposed in section [2.1](#transformations) results in a times series that looks reasonalbly (weakly) stationary as the Figure \ref{fig:stationarity} visually assures. Unit root test as the Augemented Dickey-Fuller (ADF) test or the Phillips-Perron (PP) test or other test for testing stationarity as the Kwiatkowski-Phillips-Schmidt-Shin (KPSS) test have usually very limitied explanatory power due to their sensitivity on assumptions and are thus not performed. The series is mean-centered and shows a relatively constant variance. However, two outliers, which were already evident in the original data, remain. A possible explanation for extreme values for $\bar{r}_t$ with a small $sd_t$ for the same $t$ could be volcanic activity, which has been shown to impact tree growth [@sigl2015timing]. But this would only explain the negative outlier (small ring width) (GAB ES DAMALS WIRKLICH EINEN AUSBRUCH ODER AUSBRUECHE?). 

The ACF and PACF for this stationary series (see Figure \ref{fig:acfpacf_chosen}) give further evidence for a stationarity. The other three approaches lead to less satisfactory results. In particular, the ACF decreases for these cases rather slowly.^[The ACF of a random walk shows such a pattern. However, a random walk is not stationary and thus need to be further transformed, usually by taking the difference $x_{t+1} - x_t$. In case of a random walk the resulting time series is white noise.] For the sake of brevity the results are not shown.

```{r stationarity, fig.cap="The stationary series obtained throgh scaling, log-transformation and order-1 trend removal is displayed on the left. On the right, the qq-plot of the series is shown. The series seems to be normally distributed, except for the two outliers at around 1520 and 1550.", out.width="\\linewidth"}
grid.draw(egg::ggarrange(stationaritylog_order1_plot,
    stationarity_qq_plot + theme(aspect.ratio = 1),
    ncol=2,
    widths = c(0.7,0.3)))
```

## Model selection {#modelselection}
As explained in Section [2.2] (#modelfitting) the patterns of the ACF and PACF can be used to estimate the parameters $p$ and $q$ of an ARMA(p,q) process (see Table \ref{tab:acfpacfdecision}). Figure \ref{fig:acfpacf_chosen} give some basis to argue for either an AR(1) or ARMA(1,1) process.

```{r acfpacf_chosen, fig.cap="ACF (left) and PACF (right) of the stationary time series $X_t$."}
acf <- ggAcf(data_log_order1_varstab$y, main="") +
    theme(aspect.ratio = 0.618) # looks exponential
pacf <- ggPacf(data_log_order1_varstab$y,main="") +
    theme(aspect.ratio = 0.618) 
grid.arrange(acf,pacf,ncol=2)

```

The visual guess that the process could be ARMA(1,1) is confirmed by automatic model selection methods as the `autofit` method from the `itsmr` package^[The bounds for the parameters $p$ and $q$ are set to be 0 and 3, respectively.] and the `auto.arima` method from the `forecast` package^[The bounds for the parameters $p$ and $q$ are set to be 0 and 5, respectively. These are the default values and will be later used in the `na.kalman` method of the `imputeTS` package.]. Table \ref{tab:modelaic} lists values of the AIC for the different models. ARMA(1,1) shows the best fit to the data, followed by the AR(2) model. The performance of the AR(1) model is the weakest. In Table \ref{tab:modelcomp} the estimated parameters for all models are presented. The parameters are significantly different from 0 at an $\alpha$-level of 5\% for any model. Despite the fact that ARMA(1,1) is the best model in terms of AIC (see Table \ref{tab:modelaic}), we decide to include all three model in our analysis because all of them are frequently found in the literature to fit dendrochronological data well.

```{r modelaic}
kable(model_aic_compared, booktabs=T,caption="Comparison of AIC of the fitted models.") %>%
    kable_styling(latex_options="hold_position",position="center")
```


```{r modelcomp}
kable(modelComparisonTable, booktabs=T,
      caption="Model parameters for ARMA(1,1) and AR(1).",
      escape=FALSE,
      row.names = FALSE) %>%
    kable_styling(latex_options = c("hold_position"), position = "center") %>%
    column_spec(1,bold=T)%>%
    collapse_rows(columns=c(1),headers_to_remove=c(1), latex_hline = "custom", custom_latex_hline = 1)
```

The validity of all models is further assessed graphically by plotting the standardized residuals and their ACFs. Moreover, Ljung-Box tests are perfomed for different lags to check the independence assumption. The plots are shown in Figure \ref{fig:tsdiag}. Some insights can be gainded from the results of the Ljung-Box tests. The p-values of the ARMA(1,1) model are all greater than 5\%, whereas some p-values of the AR(2) model and all of the AR(1) are smaller than 5\%. This further confirms that the ARMA(1,1) might be the best model, followed by the AR(2) model. The residuals of the AR(1) still show temporal dependencies, which is an indication that the model is too simple. 

```{r tsdiag, fig.cap="Diagnostic plots for ARMA(1,1), AR(1) and AR(2). Top: Standardized residuals, middle: ACF, bottom: Ljung-Box test",fig.width=18,fig.asp=0.618,out.width="0.7\\linewidth"}

legend_plot <- ggpubr::get_legend(boxtest_plot)

grid.draw(egg::ggarrange(residuals_plot + theme(legend.position = "none"),
    acf_comparison_plot + theme(legend.position = "none", aspect.ratio = 0.4),
    boxtest_plot + theme(legend.position = "none", aspect.ratio = 0.4),
    ncol=1,
    heights = c(1,0.8,0.8),
    top=legend_plot))

```

## Imputations {#imputaionsII}
Section [3.2] (#modelselection) give evidence that the ARMA(1,1) model describes the stochastic process best. We expect to see the same pattern when we compare the models in respect of their imputation performance. Figure \ref{tab:modelcomp} shows the MSEs (mean squared errors) for the stationary series denoted as "transformed", and the backtransformed series denoted as "original". The MSE are the results of a small simulation study, where we set 40 times one observation randomly as missing. The missing values are restricted to  be spread equally over the time series since we define 40 blocks, the first beeing from 1401 to 1409, the second from 1411 to 1419, and so forth, from which we choose randomly one value as missing. The unknown standard deviation, needed for the backtransformation, is chosen (i) from an ARMA(1,1) (model selection) or (ii) is linearly interpolated. We also do the backtransformation as if we knew the standard deviation (iii). The coefficients of the linear model needed for the backtransformation are estimated without knowing the missing value. On the transformed series, ARMA(1,1) performs best with a MSE of 0.005. However, simple linear interpolation does the job almost as accuracy. A similar pattern is seen on the original series. Assuming a ARMA(1,1) does not really outperform linear interpolation. Not surprsingly, the best results are obtained when the standard deviation is known. Simple linear interpolation on the original time series performs poorly compared to the other approaches with a MSE of 302.4. The results of the imputation are also plotted in Figure \ref{fig:imputationcomparison}.

```{r modelcompimp}
kable(modelComparisonImputationTable, booktabs=T,
      caption="MSE results of the simulation study.",
      escape=FALSE,
      row.names = FALSE) %>%
    kable_styling(latex_options = c("hold_position"), position = "center") %>%
    column_spec(1,bold=T)%>%
    collapse_rows(columns=c(1),headers_to_remove=c(1), latex_hline = "custom", custom_latex_hline = 1)
```

```{r imputationcomparison, fig.cap="Comparison of imputed values obtained through different methods."}
pplot_comparison
```

The `na.kalman` method of the `imputeTS` package, for which ARMA(1,1) processes are assumed for the transformed times series and for the standard deviation by automatic model selection using `auto.arima` from the `forecast` package, leads to similar results. Comparing the values of our implementation versus `na.kalman` gives a MSE of $\text{8.8}\cdot \text{10}^\text{5}$ for the transformed series and a MSE of 2.7 in case of the standard deviation. However, in a overall comparison the `na.kalman` performs better than our implementation by achieving a MSE of 256.1 when assumong an ARMA(1,1) for the transformed time series and the standard deviation, and equally when the standard deviation is linearly interpolated (own implementation: 274.2 vs. `na.kalman`: 275.7). The differences can may be explained by our implementation of the ARMA(1,1), where we have to add some noise to the covariance matrix of the state equation, in order to be able to estimate the model with the `dlm` package. 
